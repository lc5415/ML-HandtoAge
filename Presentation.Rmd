---
title: "Machine Learning Project - Hand-To-Age ($H_2A$)"
author: "Luis Chaves"
date: "10/03/2020"
institute: "MSc Health Data Analytics & Machine Learning"
output: 
  beamer_presentation:
    theme: "Marburg"
    slide_level: 2
outertheme: sidebar
bibliography: h2a.bib
biblio-style: apalike
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = "/Users/luischavesrodriguez/OneDrive\ -\ Imperial\ College\ London/MScHDA/Term2/ML/ML-HandtoAge")
library(ggplot2)
library(tidyverse)
library(scales)
library(ggpubr)
```

# Project description
## Data
__Data source:__ Radiology Society of North America(RSNA) and Radiology Informatics Committee (RIC). Available in Kaggle. Images gathered by several 

__Dataset:__ 12,621 images of individuals aged between 1 month and 19 years (228 months) old. Gender and age available for all fo them.

__Context:__ Images gathered for the Pediatric Bone Age ML Challenge.

## Aim(s) of my study

> __Supervised question \#1:__ How close can we estimate age from images only?

> __Supervised question \#2:__ Can gender be derived from the image?

> __Unsupervised question:__ Can clustering algorithm accurately group together individuals by gender

## Population statistics
```{r}
info = read.csv("boneage-training-dataset.csv")
dens.per.sex = info %>% ggplot(aes(boneage, fill = male))+geom_density(alpha = 0.7)+scale_fill_brewer(palette = "Accent", name = "Gender", labels = c("Female", "Male"))+theme_minimal()+ggtitle("Age distribution by gender")+ylab("Density")+xlab("Age (in months)")+theme(text=element_text(size=21))


blank_theme = theme_minimal()+theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.border = element_blank(),
  panel.grid=element_blank(),
  axis.ticks = element_blank(),
  plot.title=element_text(size=8, face="bold")
  )

pie = info %>% group_by(male) %>% 
  summarise(Proportion = n()/nrow(info)) %>% 
  ggplot(aes(x="", y=Proportion, fill=male))+
  geom_bar(width = 1, stat = "identity", show.legend = F)+coord_polar("y", start = 0)+
  geom_text(aes(y = Proportion/2 +
                  c(0, cumsum(Proportion)[-length(Proportion)]), 
                label = percent((1-Proportion)/100)), size=9)+blank_theme+theme(axis.text.x=element_blank())+scale_fill_brewer(palette = "Accent", name = "Gender", labels = c("Female", "Male"))

dens.per.sex+annotation_custom(ggplotGrob(pie), xmin = -150, ymin = 0.005)



```

## The images
X-ray images of each individuals' hand (one or two - information not available)

* Difficulties:  
    + Varying resolution (plot)  
    + Varying contrast  
    + Varying exposure
    + Some scanned and some digital images  
    
* Advantages:  
    + Standardised medical images 

Let's have a look at some pictures!

## Raw Images

![](Images/notitleRawImagesGrid.png "Raw images from the dataset")

## Raw Images

![](Images/RawImagesGrid.png "Raw images with their labels")

# Methods: Deep Learning for Computer Vision

## Data processing 
### Data split
10,000 Images for training, 2611 for testing/validation, no cross-validation because of computational cost and large amount of training data.

### Image processing
* Rescaled and Center Cropped Images:
* Centering and scaling features (pixel values)
* Contrast adjustment

## Image processing & Feature engineering (1/3)

Large disparity in image resolution therefore need to make all images same size. Default for many network architectures is 224x224 so that is our choice! Could be increased for likely better results at higher computational cost


## Image processing & Feature engineering (2/3)

It is widely recommended to normalise the inputs of a neural networks as this will speed up training by gradient descent. 
Several forms of normalisation: Instance Normalisation(IN) and Batch Normalisation(BN):

* IN: Center and scale each image w.r.t. its mean and standard deviation.
* BN: Center and scale each image w.r.t. the whole batch of images mean and standard deviation

> The (instance) normalization process allows to remove instance-specific contrast information from the content image [see @Smith2015]

## Image processing & Feature engineering

![](Images/CenterandScale.png){width=70%}![](labelled/train/1468.png){width=30%}

## Image processing & Feature engineering

![](Images/CentScaleOne.png){width=70%}![](labelled/train/1468.png){width=30%}


## Network of choice: ResNet

## Hyperparameter tuning

* Learning rate $\alpha$
* Optimizer: __SGD__, Adam
* Learning rate scheduler: StepLR, Exponential LR, ReduceONPlateauLR, __CyclicLR__, __OneCycle Policy__
* Image normalisation: batch vs instance
* Networks' depth (\# of layers): 18, 34 and 50 layer-deep ResNets
* Regularisation: L2-regularisation

## Exponentially growing possibilites

The 'Caviar' approach: training many many models with different hyperparameters, seeing which one does best. I tried:

* Varying ResNet Depth: 18, 34, 50 layers.
    + IN, $\alpha$ = 1,ExponentialLR schedule, $\gamma$ = 0.7, ADAM optimizer, no weight decay
* Changing LR schedule: ReduceOnPlateau, StepLR with different $\gamma$ (0.1 and 0.5) and stepsize (1,4,9,16,25).
* __Moving into smarter ideas:__ CyclicLR, LR Range finder and One cycle policy.


## Results 1, varying depth

```{r}
res18 = read_csv('Results/TrainTestLoss1.csv')
res34 = read_csv('Results/TrainTestLoss2.csv')
res50 = read_csv('Results/TrainTestLoss3.csv')

pBatch18 = read_csv('Results/LossPBatch1.csv')
pBatch34 = read_csv('Results/LossPBatch2.csv')
pBatch50 = read_csv('Results/LossPBatch3.csv')

res18$X1 = res34$X1 = res50$X1 = res18$X1+1
colnames(res18)[1] = colnames(res34)[1] = colnames(res50)[1] = "Epoch"

results = rbind(cbind(res18, Depth = "18"),
                cbind(res34, Depth = "34"),
                cbind(res50, Depth = "50"))

results %>% pivot_longer(-c(Epoch, Depth), names_to = "Loss", values_to = "MAE") %>%
  ggplot(aes(x = Epoch, y = MAE, color = Depth, group = Loss))+geom_line(aes(linetype = Loss))+facet_wrap(~Depth)+ylim(0,60)+theme_pubclean()
```

## Unsupervised Learning

### Umap and K-means

# Results

# Slide with R Output
## POTATO
```{r cars, echo = TRUE}
summary(cars)
```

## Slide with Plot

```{r pressure}
plot(pressure)
```

